
## types of Machine Learning
1. Supervised Learning
    - Predicts labels from labeled data (Classification, Regression)
        - Classification Algorithms
            - Logistic Regression
            - SVM
            - Naive Bayes
            - KNN
            - Decision Tree
            - Random Forest

        - Regression Algorithms
            - Linear Regression
            - Decision Tree
            - Random Forest

2. Unsupervised Learning
    - Finds hidden patterns in unlabeled data (Clustering, Dimensionality Reduction).
    - Clustering Algorithms
        - K-Means
        - Hierarchical Clustering
    - Dimensionality Reduction Algorithms
        - PCA
        - t-SNE

3. Semi-Supervised Learning
    - Combines a small amount of labeled data with a large amount of unlabeled data to enhance accuracy.
    - Techniques:
        - Self Training
        - Low Density Separation
        - Graph-based Algorithms

4. Reinforcement Learning (RL)
    - Learns through `rewards` and `penalties` to perform tasks better.
    - Reinforcement Learning from Human Feedback (RLHF)
    - Algorithms:
        - Q-Learning
        - Deep Q-Networks (DQN)
        - RL from Human Feedback (RLHF)

## Deep Learning
    - Convolutional Neural Networks (CNN)
        - Layers
            - Pooling
            - Fully-Connected
            - Max Pooling
            - Average Pooling
            - Padding

        - Techniques
            - Data Augmentation
            - Super-Pixel
            - Inception Module
            - Feature Extractor

    - Recurrent Neural Networks (RNN)
        - Challenges
            - Vanishing Gradient
            - Exploding Gradient
        - Activation Functions
            - ReLU
            - Softmax

    - Advanced Architectures
        - AlexNet
        - VGGNet
        - GoogleNet
        - ResNet
        - YOLO
        - SqueezeNet
        - SegNet
        - GANs: (e.g., U-Net, DeepLab)

## Artificial Neural Networks ( ANNs )
    - Components
        - Neuron
        - Bias
        - Node

    - Architectures
        - MLP
        - Feedforward
        - Radial Basis Functions
        - Hopfield

    - Learning Techniques
        - Forward/Backward Propagation
        - Gradient Descent


## Keywords and Concepts
0. Digital twin
    - A digital twin is a digital replica of a physical object, system, or structure (such as a factory, data center, the Earth, or a shrine), which allows us to observe and analyze it in real time.  


0. Unconditional Image Generation
    - These are models that generate new images without requiring specific input. a model like GAN.

0. Depth Estimation
    - These are models that estimate depth (3D information) from 2D images.  
    - Example: Imagine you have an image of a road‚Äîthe model estimates the depth of different objects like cars and trees.

0. Zero-Shot Image Classification
    - These are models that can classify images without being directly trained on those specific categories.
    - Example: If a model has been trained on categories like "dog" and "cat," but is able to classify an image of an "elephant" without having seen any training data for "elephant."

0. Zero-Shot Object Detection
    - These are models that can recognize an object in images without having seen specific examples of that object before.
    - Example: The model has been trained to identify "cars" and "bicycles," but is now able to recognize a "bus" without direct training on it.

0. Token Classification
    - These are models that assign each word or token in a sentence to a specific category.
    - Example: In a sentence like "Ali went to school," the model can classify "Ali" as a name and "school" as a location.


0. Table Question Answering
    - These are models that answer questions about data in tables.
    - Example: You have a table of product sales and ask, "Which product had the highest sales?"‚Äîthe model provides the answer.

0. Fill-Mask
    - These are models that fill in missing words in a sentence.
    - Example: You give the model a sentence like "The weather is [MASK]," and the model completes it as "The weather is sunny."

0. Voice Activity Detection
    - These are models that detect which parts of an audio file contain speech.
    - Example: A model that identifies segments with human speech in a long audio recording.

0. Tabular Classification
    - These are models that classify tabular data based on different categories.
    - Example: A model that classifies customer data into categories like "loyal buyer" and "regular buyer."

0. Tabular Regression
    - These are models that predict continuous values based on tabular data.
    - Example: A model that predicts the price of a house based on features like size and location.

0. Time Series Forecasting
    - These are models that predict future trends based on time series data.
    - Example: A model that forecasts how stock prices will change in the next month.

0. Model Distillation 
    - Is a technique where a big model (teacher) teaches a smaller model (student).
    - The big model is smart but slow. The small model learns from it to be fast and still good.
    - It uses the soft outputs (like 0.7 cat, 0.2 dog, 0.1 rabbit) instead of just hard labels.

0. Model Collapse
    - is a problem where a model starts giving very limited or repetitive outputs.
    - a generative model might start producing almost the same image or sentence every time.

0. Mixture of Experts (MoE)
    - is a machine learning approach where multiple specialized models (called "experts") are trained to handle different tasks. A gating model decides which expert to use for a given input.
    - The idea is to combine the strengths of different models, making the system more efficient and powerful by using the right expert for each task.


## Steps in the Machine Learning Process
1. Define the Problem
    - Determine the problem you are trying to solve (e.g., classification, regression).

2. Collect Data
    - Gather relevant data from various sources (e.g., CSV files, databases, APIs).

3. Data Preprocessing
    - Clean the data (e.g., handle missing values, correct errors).
    - Scale/normalize the data if necessary.
    - Encode categorical features.
    - Feature engineering (select/create useful features).

4. Select the Model
    - Choose the appropriate algorithm for your problem (e.g., Logistic Regression, SVM, Random Forest).

5. Split the Data
    - Divide the data into training and testing sets (e.g., 70%-30%, 80%-20%).
    - `Training Data` This is the data we give to the model so it can learn.
    - `Test Data` This is the data we give to the model to see how well it learned. It‚Äôs like an exam to check its knowledge.

6. Train the Model
    - Train the model using the training data.
      ```
        from sklearn.model_selection import train_test_split
        from sklearn.linear_model import LinearRegression
        from sklearn.datasets import make_regression
        from sklearn.metrics import mean_squared_error

        # Generate some synthetic data (features and labels)
        X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)
        
        # Step 1: Split the Data (80% training, 20% testing)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Step 2: Train the Model
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        # Step 3: Test the Model
        y_pred = model.predict(X_test)
        
        # Step 4: Evaluate the Model
        mse = mean_squared_error(y_test, y_pred)
        print(f"Mean Squared Error: {mse:.2f}")
      ```

7. Evaluate the Model
    - Evaluate the model's performance using the test data.
    - Use metrics like accuracy, precision, recall, or MSE ( Mean Squared Error ).
         #### Imagine you are trying to catch thieves.
        - `Accuracy`: Out of all the people you saw (thieves and good people), how many did you guess correctly?
        - `Precision`: Out of all the people you said are thieves, how many were actually thieves?
        - `Recall`: Out of all the real thieves, how many did you catch and not miss?

8. Tune Hyperparameters
    - `Hyperparameters` are the settings you choose before training a machine learning model.
      They help control how the model learns (e.g., Learning rate, Number of layers, Number of trees in a forest in Random Forest).
    - `Fine-tune` Trying different values for the hyperparameters to find the best combination that makes the model as accurate as possible and with the least amount of error.

9. Test and Optimize the Model
    - Test the model with new data and adjust as needed to improve performance.
    - Use techniques like cross-validation to prevent overfitting/underfitting.
        - `Overfitting` means the model learned too much, including unimportant details.
        - `Underfitting` means the model didn‚Äôt learn enough and is too simple.

10. Deploy the Model
    - Deploy the model into production to make real-time predictions.

11. Model Maintenance and Updates
    - Update and retrain the model regularly with new data to maintain its accuracy.

## ùêìùê®ùê© ùêåùêöùêúùê°ùê¢ùêßùêû ùêãùêûùêöùê´ùêßùê¢ùêßùê† ùêÄùê•ùê†ùê®ùê´ùê¢ùê≠ùê°ùê¶ùê¨

0. K-Means

    - First, we specify the number of clusters (K).
    - Then, we select K points as the initial centers and assign each data point to the nearest center.
    - After that, we calculate the mean of the points in each group and update the cluster center.
    - We repeat these steps until no further changes occur in the cluster centers.
    - Finally, the data is categorized into K similar groups.

0. Linear Regression vs Logistic Regression
    - Regression itself means predicting the changes in one variable based on the changes in another variable.
    - The `sigmoid` function is a mathematical function that takes any input and keeps its output between 0 and 1.

    - Linear Regression
        - It is used for predicting a numerical (continuous) value.
        - For example: predicting house prices, temperature, employee salary.
        - The output is a real number (e.g., 73.5).
    - Logistic Regression
        - It is used for predicting a category (class).
        - For example: Is the email spam or not? Is the person sick or healthy?
        - The output is a probability between 0 and 1.


0. Decision Tree
    - A decision tree is a machine learning model that classifies or predicts data by using a series of yes/no questions or comparisons.

0. Random Forest
    - It creates a set of decision trees (each making a prediction). By taking a vote from all the trees, it makes the final decision.

0. Naive Bayes
    - We calculate the probability of a data point belonging to each class and select the one with the highest probability.

0. KNN
    - It looks at the K nearest neighbors and makes a decision based on their votes regarding similarity.

0. SVM (Support Vector Machine)
    - SVM is a classification algorithm that finds the best line or hyperplane that separates data from different classes and tries to maximize the distance between the data points and the separating boundary.

0. Dimensionality Reduction
    - When the data has many features, these algorithms help keep only the most important ones. This makes the model faster, simpler, and more accurate.

## Kaywords
0. Digital twin
    - A digital twin is a digital replica of a physical object, system, or structure (such as a factory, data center, the Earth, or a shrine), which allows us to observe and analyze it in real time.  


0. Unconditional Image Generation
    - These are models that generate new images without requiring specific input. a model like GAN.

0. Depth Estimation
    - These are models that estimate depth (3D information) from 2D images.  
    - Example: Imagine you have an image of a road‚Äîthe model estimates the depth of different objects like cars and trees.

0. Zero-Shot Image Classification
    - These are models that can classify images without being directly trained on those specific categories.
    - Example: If a model has been trained on categories like "dog" and "cat," but is able to classify an image of an "elephant" without having seen any training data for "elephant."

0. Zero-Shot Object Detection
    - These are models that can recognize an object in images without having seen specific examples of that object before.
    - Example: The model has been trained to identify "cars" and "bicycles," but is now able to recognize a "bus" without direct training on it.

0. Token Classification
    - These are models that assign each word or token in a sentence to a specific category.
    - Example: In a sentence like "Ali went to school," the model can classify "Ali" as a name and "school" as a location.


0. Table Question Answering
    - These are models that answer questions about data in tables.
    - Example: You have a table of product sales and ask, "Which product had the highest sales?"‚Äîthe model provides the answer.

0. Fill-Mask
    - These are models that fill in missing words in a sentence.
    - Example: You give the model a sentence like "The weather is [MASK]," and the model completes it as "The weather is sunny."

0. Voice Activity Detection
    - These are models that detect which parts of an audio file contain speech.
    - Example: A model that identifies segments with human speech in a long audio recording.

0. Tabular Classification
    - These are models that classify tabular data based on different categories.
    - Example: A model that classifies customer data into categories like "loyal buyer" and "regular buyer."

0. Tabular Regression
    - These are models that predict continuous values based on tabular data.
    - Example: A model that predicts the price of a house based on features like size and location.

0. Time Series Forecasting
    - These are models that predict future trends based on time series data.
    - Example: A model that forecasts how stock prices will change in the next month.

0. Model Distillation 
    - Is a technique where a big model (teacher) teaches a smaller model (student).
    - The big model is smart but slow. The small model learns from it to be fast and still good.
    - It uses the soft outputs (like 0.7 cat, 0.2 dog, 0.1 rabbit) instead of just hard labels.

0. Model Collapse
    - is a problem where a model starts giving very limited or repetitive outputs.
    - a generative model might start producing almost the same image or sentence every time.

0. Mixture of Experts (MoE)
    - is a machine learning approach where multiple specialized models (called "experts") are trained to handle different tasks. A gating model decides which expert to use for a given input.
    - The idea is to combine the strengths of different models, making the system more efficient and powerful by using the right expert for each task.

## Recommendation Systems (RS)
0. Recommendation Systems
    -  A system that suggests items (like movies, products, or songs) to users based on their preferences and behavior.

## Tools
    - ML and Data Analysis
        - Numpy
        - Pandas
        - Matplotlib
        - Scikit-learn
        - TensorFlow
        - Keras
        - PyTorch

    - Data Visualization
        - Seaborn
        - Plotly

    - Deep Learning Frameworks
        - Jupyter
        - PySpark
        - Polar

    - Image Processing
        - YOLO
        - Detectron2
        - MediaPipe

    - Vector Databases
        - Pinecone
        - Weaviate

    - Text Processing
        - NLP tools and models

    - crypto currency
        - `Pine Script` Is a lightweight programming language created by `TradingView` for writing custom indicators, strategies, and alerts on     financial charts. It's easy to learn and allows traders to automate technical analysis directly within the TradingView platform.